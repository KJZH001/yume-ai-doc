# 大语言模型聚合接口
这个接口允许你通过修改不同的参数，来实现调用我们所有支持的模型

和我们的私有的`MoeChat`协议接口不同，这个接口保持了和`Openai`官方接口的一致性

你可以在[这里](https://beta.openai.com/docs/api-reference/completions/create)查看官方的接口定义

或者，你也可以在[这里](https://openai.apifox.cn/api-67883981)查看国内镜像版本的**中文**文档

## 接口地址
```url
https://api.moeworld.top/api/openai/index.php?web=true&
```
这是完整的接口地址，你可以直接使用它

同时，你可能也已经在`在线面板`的使用文档中看到了这个地址，没错，它们是一样的

## 接口参数
因为使用方法和官方的接口一致，所以这里不再赘述

如果需要，你可以去查阅官方的文档，或者你只是想快速调用的话，也可去`大语言模型/概述`一节去查看我们对于使用方法的大致说明

这里我们只讲一些需要注意的地方，以及不同之处

### 基本地址
```url
https://api.moeworld.top/api/openai/index.php
```
这一部分是最基本的地址，你可以直接使用它，也可以在后面加上参数

但是请注意，不要去掉index.php，否则将会容易导致出现一些意外的问题

### 可选参数
```url
?web=true&
```
正如你所见的，它是一个GET参数，你可以在后面加上它，也可以不加

如果你不加，那么你将会得到一个JSON格式的回复，这个回复将会是一个标准的Openai接口回复

如果添加了web=true，那么你会得到一个仅包含文本的回复，这个回复将会是一个纯文本

对应的是Openai接口回复中的`choices`字段的`message`字段的`content`字段的值

也就是GPT或者其他的模型返回给用户可被理解的文本

这么说可能有点抽象，下面我们来看一下具体的例子

```json
{
    "id": "chatcmpl-7oqoflxUbLGTN6rWApmbCMjPX9Hzj",
    "object": "chat.completion",
    "created": 1692353781,
    "model": "gpt-35-turbo",
    "choices": [
        {
            "index": 0,
            "finish_reason": "stop",
            "message": {
                "role": "assistant",
                "content": "你好啊！有需要我帮忙的吗？"
            }
        }
    ],
    "usage": {
        "completion_tokens": 16,
        "prompt_tokens": 11,
        "total_tokens": 27
    }
}
```
以这段标准的Openai接口回复的json为例

如果提交的get参数中，web=true，那么你将会得到这样的回复

```text
你好啊！有需要我帮忙的吗？
```

是的，只有这一句话，这就是我们所说的纯文本回复，也就是返回给用户可被理解的文本

#### 这个参数的其他部分有什么用呢？
`?`的作用不必多说，是为了让服务器知道从这里开始就是参数了

`&`的作用是让调用接口的一方可以随意往url后面添加路径，而不必担心会出现问题

毕竟有些程序你无法控制它会往url后面添加什么参数

举个例子，实际调用的时候可能你的路径会变成这样

```url
https://api.moeworld.top/api/openai/index.php?web=true&/v1/chat/completions
```

这样也是可以的，因为`&`的作用就是让你可以随意添加路径

## 切换模型

首先咱们还是以官方的这段json请求体为例
```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {
      "role": "user",
      "content": "你好！"
    }
  ]
}
```
在这个接口中，我们可以看到，我们可以通过`model`字段来切换模型，这一点和官方的接口是一致的

如果你将它修改为`glm`，那么将会调用chatglm模型

在后续模型增多以后，我们会单独做出一个页面用于查阅所有模型的名称

## 特性
由于ChatGPT next web强制使用流式传输，但是这样会导致我们的接口出现一些问题（我们的接口目前还无法使用流式传输）

所以我们在这里做了一些特殊的处理，使得我们的接口可以正常使用

### 关于流式传输
这里是官方接口的一些说明

```text
stream boolean 可选
如果设置，将发送部分消息增量，就像在 ChatGPT 中一样。当令牌可用时，令牌将作为纯数据服务器发送事件data: [DONE]发送，流由消息终止。有关示例代码，请参阅 OpenAI Cookbook 。
```

如果你想要启用流式传输，那么你需要在请求体中加上`stream=true`这个参数

### 关于流式传输的处理
我们的接口会强制舍弃`stream`参数，因为我们的接口无法使用流式传输，所以不论你提交为什么，我们会将它强制设置为`false`

这样在一定程度上解决了我们的接口无法使用流式传输产生的兼容性的问题

关于流式传输，请等待后续的更新，我们可能会在将来解决这个问题

但是就开发调用而言，我们认为用到它的地方并不多（比如说对接聊天平台的bot，有几个平台是允许流式传输的吗？）